# NLP to SQL Agent (Schema-Aware, RAG-Based)

An end-to-end **Natural Language to SQL** system that allows users to query a relational database using plain English.  
The system uses **schema-aware retrieval (RAG)**, **LLM-based SQL generation**, and **LangGraph orchestration** with validation and retry logic.

This project is designed as a **multi-user async API**, focusing on correctness, safety, and extensibility rather than prompt-only SQL generation.

---

## âœ¨ Key Features

- ğŸ§  **Schema-Aware RAG**
  - Database schema is embedded and stored in a vector database (ChromaDB)
  - Only relevant tables & columns are exposed to the LLM

- ğŸ” **Iterative SQL Repair**
  - SQL execution errors are fed back to the LLM
  - Automatic retries using LangGraph conditional routing

- ğŸ›¡ï¸ **SQL Safety Validation**
  - Blocks unsafe queries (`DROP`, `DELETE`, `UPDATE`, etc.)
  - Read-only query enforcement

- âš¡ **Async, Multi-user API**
  - Built using FastAPI + async LLM calls
  - Shared resources (LLM, embeddings, vector store) loaded once

- ğŸ§© **Modular & Extensible Design**
  - Clear separation of concerns
  - Easy to add new validators, databases, or LLMs

---

## ğŸ—ï¸ Architecture Overview

**High-level flow:**

User Question
â†“
Question Embedding
â†“
Schema Retrieval (ChromaDB)
â†“
Schema Pruning
â†“
LLM SQL Generation
â†“
SQL Validation
â†“
SQL Execution
â†“
Result Summarization


**Core technologies used:**
- FastAPI
- LangGraph
- LangChain (ChatOpenAI)
- ChromaDB
- SentenceTransformers
- SQLAlchemy (SQLite)

---

NLP_TO_SQL/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/          # Request/response schemas
â”‚   â”œâ”€â”€ core/         # Dependency container
â”‚   â”œâ”€â”€ db/           # DB engine & executor
â”‚   â”œâ”€â”€ graph/        # LangGraph state machine
â”‚   â”œâ”€â”€ llm/          # LLM client abstraction
â”‚   â”œâ”€â”€ rag/          # Schema documents, embeddings, vector store
â”‚   â”œâ”€â”€ prompts/      # Prompt templates
â”‚   â”œâ”€â”€ services/     # High-level agent service
â”‚   â”œâ”€â”€ tools/        # Utilities (SQL parsing, schema utils)
â”‚   â””â”€â”€ logger/       # Structured JSON logging
â”œâ”€â”€ init_db.py         # Database initialization (run once)
â”œâ”€â”€ main.py            # FastAPI entrypoint
â”œâ”€â”€ .env.example       # Environment variable template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md





---

## âš™ï¸ Environment Setup

### 1ï¸âƒ£ Clone the repository
```bash
git clone <repo-url>
cd NLP_TO_SQL

2ï¸âƒ£ Create virtual environment
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Configure environment variables
Create .env from template:
cp .env.example .env
Update .env:
OPENAI_API_KEY=your_api_key_here
MODEL_NAME=gpt-4o-mini

ğŸ—„ï¸ Database Initialization
Run once to create and seed the database:
python init_db.py

The script:

Creates tables if they donâ€™t exist

Inserts sample data only if the table is empty

Prevents data duplication on re-runs

ğŸš€ Running the API
uvicorn main:app --reload

API will be available at:
http://localhost:8000

ğŸ” Example API Usage
Endpoint
POST /query

Request
{
  "question": "What is the average salary in Engineering?"
}

Response
{
  "result": {
    "question": "What is the average salary in Engineering?",
    "sql": "SELECT AVG(salary) FROM employees WHERE department = 'Engineering';",
    "answer": "The average salary in the Engineering department is 90,000."
  }
}

ğŸ§ª Error Handling & Retries

SQL execution failures are captured

Error message is fed back to the LLM

Query is regenerated (up to 2 retries)

Controlled using LangGraph conditional edges

ğŸ§  Design Decisions
Why Schema RAG?

Prevents hallucinated tables/columns

Reduces token usage

Improves SQL correctness

Why LangGraph?

Explicit state transitions

Deterministic retry logic

Easier debugging vs linear chains

Why Shared Resources?

Embeddings, schema, and vector store are loaded once

Supports concurrent users efficiently

ğŸš§ Known Limitations / Future Improvements

SQL parser-based validation (planned)

Column-level semantic validation

Support for JOIN-heavy queries

Pagination & large result handling

Support for PostgreSQL / MySQL

Authentication & rate limiting

ğŸ‘¨â€ğŸ’» Author

Kailas
AI Engineer | Conversational AI | NLP â†’ SQL Systems
Focused on building robust, production-ready AI agents

ğŸ“œ License

This project is for learning, evaluation, and demonstration purposes.
